{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import json\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from gym import wrappers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env.StockTradingEnv import StockTradingEnv\n",
    "from networks.DQNac import MyModel\n",
    "from networks.DQNac import StockActor, StockCritic, DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[[[[2.74107200e-04 2.60714200e-04 2.72321400e-04 2.66071400e-04\n",
      "    2.72321400e-04 2.75446400e-04]\n",
      "   [2.77678600e-04 2.84821400e-04 2.76785800e-04 2.69642800e-04\n",
      "    2.81250000e-04 2.77678600e-04]\n",
      "   [2.59821400e-04 2.60714200e-04 2.57142800e-04 2.60714200e-04\n",
      "    2.65178600e-04 2.66964200e-04]\n",
      "   [2.61607200e-04 2.69642800e-04 2.68750000e-04 2.68750000e-04\n",
      "    2.78571400e-04 2.76785800e-04]\n",
      "   [3.66584398e-02 4.54320573e-02 5.02869487e-02 3.42104584e-02\n",
      "    2.40325928e-02 4.05726023e-02]\n",
=======
      "[[[[1.10885720e-03 1.04628580e-03 1.00000000e-03 1.04571420e-03\n",
      "    1.07600000e-03 1.04000000e-03]\n",
      "   [1.13028580e-03 1.06428580e-03 1.03714280e-03 1.06971420e-03\n",
      "    1.07828560e-03 1.06314280e-03]\n",
      "   [1.05257140e-03 1.00800000e-03 9.71428600e-04 1.02485720e-03\n",
      "    1.01257140e-03 1.02571440e-03]\n",
      "   [1.06457140e-03 1.01000000e-03 1.01771440e-03 1.05971440e-03\n",
      "    1.01457140e-03 1.06228580e-03]\n",
      "   [3.20513779e-01 2.01175828e-01 1.54503807e-01 1.25919795e-01\n",
      "    1.10027799e-01 8.84281937e-02]\n",
>>>>>>> master
      "   [4.65661288e-06 4.65661288e-06 0.00000000e+00 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]]]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/AAPL.csv')\n",
    "df = df.sort_values('Date')\n",
    "\n",
    "# The algorithms require a vectorized environment to run\n",
    "env = StockTradingEnv(df)\n",
    "\n",
    "base_action = np.array([0,0.5])\n",
    "\n",
    "obs = env.reset()\n",
    "for i in range(5):\n",
    "    action, _states = (base_action, None)\n",
    "    obs, rewards, done, info = env.step(action)\n",
    "#print(obs)\n",
    "obs = env.reset()\n",
    "obs=np.expand_dims(obs,axis=0)\n",
    "obs=np.expand_dims(obs,axis=0)\n",
    "print(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mod = MyModel(32, (1,4), (1,1))\n",
    "\n",
    "print(obs)\n",
    "z = mod.predict(obs)\n",
    "print(z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "act = StockActor()\n",
    "act_target = StockActor()\n",
    "output_action = act(obs)\n",
    "output_action_tar = act_target(obs)\n",
    "print(\"output_action\")\n",
    "print(output_action)\n",
    "print(\" \")\n",
    "print(\"output_action_tar\")\n",
    "print(output_action_tar)\n",
    "print(\" \")\n",
    "output_action = act(obs)\n",
    "output_action_tar = act_target(obs)\n",
    "print(\"output_action2\")\n",
    "print(tf.squeeze(output_action))\n",
    "print(\" \")\n",
    "print(\"output_action_tar2\")\n",
    "print(output_action_tar)\n",
    "print(\" \")\n",
    "\n",
    "#act.model.summary()\n",
    "#print(act.model.layers[3].get_weights())\n",
    "#act.model.layers[3].set_weights([np.array([[-0.3]], dtype=np.float32), np.array([0.1], dtype=np.float32)])\n",
    "#print(act.model.layers[3].get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "crit = StockCritic()\n",
    "act = StockActor()\n",
    "\n",
    "output_action = act(obs)\n",
    "print(output_action)\n",
    "output_action = tf.squeeze(output_action)\n",
    "output_crit = crit([obs,output_action])\n",
    "print(output_crit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "gamma = 0.99\n",
    "max_experiences = 1000\n",
    "min_experiences = 365\n",
    "batch_size = 32\n",
    "lr = 1e-2\n",
    "D = DQN( gamma, max_experiences, min_experiences, batch_size, lr)\n",
    "observations = env.reset()\n",
    "observations = np.expand_dims(observations,axis=0)\n",
    "observations = np.expand_dims(observations,axis=0)\n",
    "D.act(observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a = act.model.trainable_variables\n",
    "print(a)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" hjkbedfhugqdfhiqdfbhiqdf\")\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "b = act.trainable_variables\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#model = MyModel(32, (1,4), (1,1))\n",
    "#output=tf.squeeze(model(obs))\n",
    "\n",
    "crit = StockCritic()\n",
    "crit_tar = StockCritic()\n",
    "crit.action = tf.squeeze(output_action)\n",
    "crit_tar.action = tf.squeeze(output_action)\n",
    "output = crit(obs)\n",
    "output_tar = crit_tar(obs)\n",
    "print(\"output\")\n",
    "print(output)\n",
    "print(\" \")\n",
    "print(\"output_tar\")\n",
    "print(output_tar)\n",
    "print(\" \")\n",
    "crit.action = tf.squeeze(output_action_tar)\n",
    "crit_tar.action = tf.squeeze(output_action)\n",
    "output = crit(obs)\n",
    "output_tar = crit_tar(obs)\n",
    "print(\"output2\")\n",
    "print(output)\n",
    "print(\" \")\n",
    "print(\"output_tar2\")\n",
    "print(output_tar)\n",
    "print(\" \")\n",
    "print(crit.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fill_buffer(env, DQN):\n",
    "    \n",
    "    rewards = 0\n",
    "    iter = 0\n",
    "    done = False\n",
    "    observations = env.reset()\n",
    "    observations = np.expand_dims(observations,axis=0)\n",
    "    observations = np.expand_dims(observations,axis=0)\n",
    "    steps = 0\n",
    "    it=0\n",
    "    while it<DQN.min_experiences:\n",
    "        \n",
    "        #print(it)\n",
    "        #observations = env.reset()\n",
    "\n",
    "        action = DQN.act(observations) # observations is actually a single \"state\" ie past 5 days\n",
    "        action = np.tanh(tf.squeeze(action)+np.random.normal(0,0.05)) #avoiding small action values in the begining ->[2 0] to frequently\n",
    "        #print(action)\n",
    "        action = DQN.convert_action(action)\n",
    "         \n",
    "        #print(action)\n",
    "        prev_observations = observations\n",
    "        observations, reward, done, _ = env.step(action)\n",
    "        #print(reward)\n",
    "        observations = np.expand_dims(observations,axis=0)\n",
    "        observations = np.expand_dims(observations,axis=0)\n",
    "        rewards += reward    # sum of gain_net_worth\n",
    "\n",
    "        if done :\n",
    "            print(\"DONE\")\n",
    "#             reward = -200\n",
    "            env.reset()\n",
    "        steps += 1\n",
    "        if steps >= 300: # Limiting the number of steps\n",
    "            print(\"STEPS\")\n",
    "            observations = env.reset()\n",
    "            observations = np.expand_dims(observations,axis=0)\n",
    "            observations = np.expand_dims(observations,axis=0)\n",
    "            steps = 0\n",
    "        \n",
    "        obs = tf.squeeze(observations)\n",
    "        obs = np.expand_dims(obs,axis=0)\n",
    "        prev_observations = tf.convert_to_tensor(prev_observations)\n",
    "        prev_observations = tf.squeeze(prev_observations, axis=0)\n",
    "        exp = {'s': prev_observations, 'a': action, 'r': reward, 's2': obs, 'done': done}\n",
    "        DQN.add_experience(exp)\n",
    "        \n",
    "        it += 1\n",
    "    return \" Done \"\n",
    "\n",
    "def DDPG():\n",
    "    \n",
    "    gamma = 0.99\n",
    "    max_experiences = 1000\n",
    "    min_experiences = 365\n",
    "    batch_size = 32\n",
    "    lr = 1e-2\n",
    "    \n",
    "    M = 1\n",
    "    T = 1\n",
    " \n",
    "    D = DQN( gamma, max_experiences, min_experiences, batch_size, lr)\n",
    "    a = fill_buffer(env, D)\n",
    "    #print(a)\n",
    "    \n",
    "    for i in range(M):\n",
    "        D.train(env,T)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer stock_actor_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "STEPS\n",
      "WARNING:tensorflow:Layer stock_actor_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
<<<<<<< HEAD
      "[<tf.Tensor: shape=(32, 1, 6, 6), dtype=float64, numpy=\n",
      "array([[[[2.54464200e-04, 2.77678600e-04, 2.72321400e-04,\n",
      "          2.75892800e-04, 2.94642800e-04, 2.93750000e-04],\n",
      "         [2.67857200e-04, 2.79464200e-04, 2.80357200e-04,\n",
      "          2.99107200e-04, 2.95535800e-04, 2.93750000e-04],\n",
      "         [2.51785800e-04, 2.66964200e-04, 2.63392800e-04,\n",
      "          2.72321400e-04, 2.79464200e-04, 2.82142800e-04],\n",
      "         [2.66964200e-04, 2.78571400e-04, 2.75000000e-04,\n",
      "          2.92857200e-04, 2.92857200e-04, 2.84821400e-04],\n",
      "         [1.42842811e-01, 9.04155896e-02, 6.04576431e-02,\n",
      "          1.02390815e-01, 8.34804029e-02, 5.70096076e-02],\n",
      "         [1.35320301e-06, 5.36509941e-06, 1.58650801e-06,\n",
      "          2.95100982e-04, 3.33180651e-06, 1.86138068e-09]]],\n",
=======
      "WARNING:tensorflow:Layer stock_critic_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
>>>>>>> master
      "\n",
      "\n",
      "       [[[6.69642800e-04, 6.66517800e-04, 6.56919600e-04,\n",
      "          6.68750000e-04, 6.97321400e-04, 6.91071400e-04],\n",
      "         [7.12500000e-04, 6.80357200e-04, 6.91071400e-04,\n",
      "          6.92857200e-04, 7.03571400e-04, 6.99553600e-04],\n",
      "         [6.35714200e-04, 6.40625000e-04, 6.45089200e-04,\n",
      "          6.54464200e-04, 6.65178600e-04, 6.74107200e-04],\n",
      "         [6.61160800e-04, 6.52232200e-04, 6.63392800e-04,\n",
      "          6.89732200e-04, 6.77232200e-04, 6.83928600e-04],\n",
      "         [9.22996551e-02, 3.76800075e-02, 6.11741096e-02,\n",
      "          3.92341986e-02, 2.77681276e-02, 2.93783844e-02],\n",
      "         [2.03528061e-06, 5.36509941e-06, 7.12927431e-07,\n",
      "          7.72686593e-04, 8.67061317e-07, 7.11874999e-10]]],\n",
      "\n",
      "\n",
      "       [[[1.17142860e-02, 1.18557144e-02, 1.19934288e-02,\n",
      "          1.21571426e-02, 1.21688568e-02, 1.20765716e-02],\n",
      "         [1.18480004e-02, 1.19585716e-02, 1.20785714e-02,\n",
      "          1.22214286e-02, 1.21714286e-02, 1.20814286e-02],\n",
      "         [1.16937142e-02, 1.17905716e-02, 1.19777146e-02,\n",
      "          1.20385712e-02, 1.20428574e-02, 1.19802856e-02],\n",
      "         [1.18125718e-02, 1.19437142e-02, 1.20685714e-02,\n",
      "          1.20494286e-02, 1.20925712e-02, 1.20728570e-02],\n",
      "         [3.02705448e-02, 3.15799378e-02, 3.70541588e-02,\n",
      "          4.58704774e-02, 3.00580170e-02, 2.50391662e-02],\n",
      "         [4.21330827e-06, 4.67694986e-06, 7.91624189e-09,\n",
      "          1.11998751e-02, 0.00000000e+00, 0.00000000e+00]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[6.91071400e-04, 6.88392800e-04, 6.51339200e-04,\n",
      "          6.76339200e-04, 6.51785800e-04, 6.67857200e-04],\n",
      "         [6.99553600e-04, 6.88839200e-04, 6.76339200e-04,\n",
      "          6.87500000e-04, 6.66964200e-04, 6.69642800e-04],\n",
      "         [6.74107200e-04, 6.49107200e-04, 6.29910800e-04,\n",
      "          6.43750000e-04, 6.35714200e-04, 6.36160800e-04],\n",
      "         [6.83928600e-04, 6.51339200e-04, 6.75000000e-04,\n",
      "          6.45982200e-04, 6.59821400e-04, 6.51339200e-04],\n",
      "         [2.93783844e-02, 3.37997452e-02, 4.09148634e-02,\n",
      "          3.22990120e-02, 2.89376825e-02, 3.53395939e-02],\n",
      "         [1.89470859e-06, 5.36509941e-06, 7.54836947e-07,\n",
      "          7.60336564e-04, 9.23406333e-07, 7.49892143e-10]]],\n",
      "\n",
      "\n",
<<<<<<< HEAD
      "       [[[2.74107200e-04, 2.60714200e-04, 2.72321400e-04,\n",
      "          2.66071400e-04, 2.72321400e-04, 2.75446400e-04],\n",
      "         [2.77678600e-04, 2.84821400e-04, 2.76785800e-04,\n",
      "          2.69642800e-04, 2.81250000e-04, 2.77678600e-04],\n",
      "         [2.59821400e-04, 2.60714200e-04, 2.57142800e-04,\n",
      "          2.60714200e-04, 2.65178600e-04, 2.66964200e-04],\n",
      "         [2.61607200e-04, 2.69642800e-04, 2.68750000e-04,\n",
      "          2.68750000e-04, 2.78571400e-04, 2.76785800e-04],\n",
      "         [3.66584398e-02, 4.54320573e-02, 5.02869487e-02,\n",
      "          3.42104584e-02, 2.40325928e-02, 4.05726023e-02],\n",
      "         [1.70570905e-06, 5.36509941e-06, 1.34017319e-06,\n",
      "          2.92190035e-04, 3.92412767e-06, 2.02985706e-09]]],\n",
      "\n",
      "\n",
      "       [[[8.50000000e-04, 7.96428600e-04, 7.80803600e-04,\n",
      "          7.82142800e-04, 8.82142800e-04, 9.01339200e-04],\n",
      "         [8.50000000e-04, 8.57142800e-04, 8.42857200e-04,\n",
      "          8.85267800e-04, 9.06250000e-04, 9.30357200e-04],\n",
      "         [7.49107200e-04, 7.75000000e-04, 7.78571400e-04,\n",
      "          7.79017800e-04, 8.52678600e-04, 8.55357200e-04],\n",
      "         [7.80357200e-04, 8.12946400e-04, 7.99107200e-04,\n",
      "          8.84821400e-04, 9.06250000e-04, 8.65178600e-04],\n",
      "         [1.09562650e-01, 6.16800040e-02, 7.77212903e-02,\n",
      "          4.76792455e-02, 4.55096364e-02, 6.05534762e-02],\n",
      "         [2.94862559e-06, 5.36509941e-06, 4.65661288e-07,\n",
      "          8.33973978e-04, 5.90924174e-07, 5.05110183e-10]]]])>, <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "array([ 0.01275682,  0.01612215,  0.00194865,  0.00397338,  0.09927136,\n",
      "        0.01248385,  0.02354031,  0.00023461,  0.00017871, -0.00026833,\n",
      "        0.00920211,  0.02686546, -0.07957342,  0.01508469, -0.00424343,\n",
      "        0.00090981, -0.00033435,  0.00431467, -0.00069771, -0.00014737,\n",
      "       -0.00442885,  0.01603389,  0.01519793,  0.0052708 ,  0.00249374,\n",
      "        0.01219318,  0.00782243,  0.00017319,  0.00010939,  0.00505016,\n",
      "        0.00767774,  0.01653552], dtype=float32)>]\n",
      "WARNING:tensorflow:Layer stock_critic_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
=======
      "Y\n",
      "tf.Tensor(\n",
      "[ -42.282032    34.499798    52.638794    70.70893     42.12955\n",
      "  -25.089024   -63.817112    -8.917758    31.91623    186.2087\n",
      " -102.39142     24.355892     1.2783009   20.873152    12.316515\n",
      " -206.85373    -13.171479   -12.814759   -20.74508    -59.64757\n",
      "   24.299639   -23.992397   -17.879992    31.5689     -31.036459\n",
      "   24.299639   -39.10711    -74.6174      82.59657     -6.437523\n",
      "    4.1344867  -39.866318 ], shape=(32,), dtype=float32)\n",
      "WARNING:tensorflow:Layer stock_critic_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
>>>>>>> master
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
<<<<<<< HEAD
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Shapes of all inputs must match: values[0].shape = [2] != values[2].shape = [32] [Op:Pack] name: packed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-58d0c5c70b23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mDDPG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-6c770d70b313>\u001b[0m in \u001b[0;36mDDPG\u001b[1;34m()\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\reinforcement-learning-master\\P3A-Deep-Reinforcement-Learning\\Stock-Trading-Environment\\networks\\DQNac.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, env, T)\u001b[0m\n\u001b[0;32m    203\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates_act\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m             \u001b[0mvalue_next\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrit_tar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates_act\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_next\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[0mvalue_next\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_next\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\reinforcement-learning-master\\venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    821\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 822\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\reinforcement-learning-master\\P3A-Deep-Reinforcement-Learning\\Stock-Trading-Environment\\networks\\DQNac.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\reinforcement-learning-master\\venv\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m   1254\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1255\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1256\u001b[1;33m       as_ref=False)\n\u001b[0m\u001b[0;32m   1257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\reinforcement-learning-master\\venv\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1314\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\reinforcement-learning-master\\venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_autopacking_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m   1366\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m     \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_cast_nested_seqs_to_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1368\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0m_autopacking_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m\"packed\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\reinforcement-learning-master\\venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_autopacking_helper\u001b[1;34m(list_or_tuple, dtype, name)\u001b[0m\n\u001b[0;32m   1272\u001b[0m     \u001b[1;31m# checking.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1273\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_dense_tensor_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist_or_tuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1274\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_or_tuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1275\u001b[0m   \u001b[0mmust_pack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m   \u001b[0mconverted_elems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\reinforcement-learning-master\\venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mpack\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   5691\u001b[0m         \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5692\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5693\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5694\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5695\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\reinforcement-learning-master\\venv\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6605\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6606\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6607\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\reinforcement-learning-master\\venv\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Shapes of all inputs must match: values[0].shape = [2] != values[2].shape = [32] [Op:Pack] name: packed"
=======
      "\n",
      "Qval\n",
      "tf.Tensor(\n",
      "[ 0.01997677  0.0232862   0.10002328  0.10015214 -0.06366175  0.0212152\n",
      "  0.02829986 -0.02733597  0.06461024  0.12850782  0.03914462  0.02789402\n",
      "  0.0447955  -0.03401501  0.09666131  0.02886529  0.11337422 -0.14192449\n",
      "  0.02613943  0.05659364 -0.16034935 -0.08677597 -0.01005187  0.11757797\n",
      " -0.1765811  -0.16034935 -0.05550531  0.13973159  0.02097721  0.07532857\n",
      "  0.06305545  0.00505826], shape=(32,), dtype=float32)\n",
      "loss\n",
      "tf.Tensor(131345.81, shape=(), dtype=float32)\n",
      "Done optimize crit\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "gradient() missing 1 required positional argument: 'sources'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-58d0c5c70b23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mDDPG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-35aaf38a0659>\u001b[0m in \u001b[0;36mDDPG\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[0mD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\reinforcement-learning-master\\P3A-Deep-Reinforcement-Learning\\Stock-Trading-Environment\\networks\\DQNac.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, env, T)\u001b[0m\n\u001b[0;32m    252\u001b[0m             \u001b[0mact_variables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m             \u001b[0mcritic_grad_act\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#gradient of the critic network w.r.t the act network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcritic_grad_act\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: gradient() missing 1 required positional argument: 'sources'"
>>>>>>> master
     ]
    }
   ],
   "source": [
    "DDPG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (reinforcement-learning-master)",
   "language": "python",
   "name": "pycharm-7a748578"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
