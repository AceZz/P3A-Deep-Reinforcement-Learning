{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import json\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from gym import wrappers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env.StockTradingEnv import StockTradingEnv\n",
    "from networks.DQNac import MyModel\n",
    "from networks.DQNac import StockActor, StockCritic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1.26428580e-03 1.26771440e-03 1.22171440e-03 1.22285720e-03\n",
      "    1.19714280e-03 1.13257140e-03]\n",
      "   [1.28257140e-03 1.26885700e-03 1.22885720e-03 1.23571420e-03\n",
      "    1.20457140e-03 1.15085720e-03]\n",
      "   [1.25942860e-03 1.17771420e-03 1.19571420e-03 1.21000000e-03\n",
      "    1.14571420e-03 1.10942860e-03]\n",
      "   [1.26057140e-03 1.19400000e-03 1.22314280e-03 1.22142860e-03\n",
      "    1.15800000e-03 1.12428560e-03]\n",
      "   [5.33369836e-02 1.64338108e-01 8.80820211e-02 5.24604693e-02\n",
      "    1.18912570e-01 1.53955212e-01]\n",
      "   [1.49073246e-07 4.70588215e-06 7.11996109e-07 1.26616974e-03\n",
      "    0.00000000e+00 0.00000000e+00]]]]\n",
      "tf.Tensor([[0.00011476]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/AAPL.csv')\n",
    "df = df.sort_values('Date')\n",
    "\n",
    "# The algorithms require a vectorized environment to run\n",
    "env = StockTradingEnv(df)\n",
    "\n",
    "base_action = np.array([0,0.5])\n",
    "\n",
    "obs = env.reset()\n",
    "for i in range(5):\n",
    "    action, _states = (base_action, None)\n",
    "    obs, rewards, done, info = env.step(action)\n",
    "    \n",
    "obs=np.expand_dims(obs,axis=0)\n",
    "obs=np.expand_dims(obs,axis=0)\n",
    "print(obs)\n",
    "\n",
    "#model = MyModel(32, (1,4), (1,1))\n",
    "#output=tf.squeeze(model(obs))\n",
    "\n",
    "act = StockActor()\n",
    "output_action=act.predict(obs)\n",
    "\n",
    "#crit= StockCritic(output_action)\n",
    "#output=crit.build_critic(obs)\n",
    "\n",
    "print(output_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (reinforcement-learning-master)",
   "language": "python",
   "name": "pycharm-7a748578"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
